import MdxLayout from "../../../components/mdx-layout";
import { CodeBlock } from "../../../components/code-block";
import { BEYOND_VIBE_CODING } from "../../../lib/state/blog";

export const metadata = {
  title: BEYOND_VIBE_CODING.title,
  date: BEYOND_VIBE_CODING.date,
  description:
    "I was vibe coding and getting slower with AI. Then I discovered Claude Code's hooks and parallel workflows, and everything changed. Here's what I learned about building a structured AI development workflow.",
  keywords:
    "AI development workflow, Claude Code, vibe coding, developer productivity, AI automation, custom hooks, Claude Code Web, AI-assisted development, workflow automation, development efficiency",
  category: "AI Development",
  readTime: "14 min read",
  author: "Johannes Mändle",
};

# {metadata.title}

<div className="text-center py-8 bg-gradient-to-r from-blue-50 to-purple-50 rounded-lg mb-8">
  <div className="max-w-3xl mx-auto px-6">
    <h2 className="text-2xl font-bold mb-4">The AI Productivity Paradox</h2>
    <p className="text-lg text-muted-foreground mb-6">
      I spend about 2+ hours daily working with AI tools, like most developers these days.
      But here's what surprised me: research shows **experienced developers actually take 19% longer** when using AI—while believing they're 20% faster.
      I was probably one of them.
    </p>
  </div>
</div>

## My Journey from Vibe Coding to Structured AI Development

Earlier this year, I came across Addy Osmani's term **"vibe coding"**—that playful approach where you throw high-level prompts at AI, accept whatever comes back, and focus on whether it "feels right" rather than whether it's actually maintainable.

I'll be honest: I was doing exactly this. It felt fast. It felt productive. Looking back, it was creating a mess in my codebase.

### What I Was Actually Doing

Looking back, my "vibe coding" workflow looked like this:
- Tossing broad, high-level instructions at AI
- Accepting suggestions without actually reading the generated code
- Asking myself "does it feel right?" instead of "is this maintainable?"
- Skipping my usual testing and code review habits

When I read Osmani's book *Beyond Vibe Coding: From Coder to AI-Era Developer*, I realized he wasn't promoting this approach—he was warning us to move **beyond it**. That hit home.

### The Wake-Up Call

The research I found was humbling:

**What actually happens:**
- Experienced developers take **19% longer** to complete tasks with AI (not faster!)
- **45% of developers** say debugging AI code takes longer than writing it themselves
- Only **3% express high trust** in AI-generated code
- **One in five AI suggestions contains errors**

**Why my vibe coding approach was failing:**
- I had no systematic code review process
- The AI lacked context, so suggestions didn't fit my codebase
- Technical debt was piling up invisibly
- I nearly committed API keys twice

## How I Rebuilt My Workflow with Claude Code

I realized I needed to stop choosing between "AI does everything" or "I do everything"—I needed to **orchestrate AI as part of my existing workflow**.

That's when I discovered **Claude Code**, and it fundamentally changed how I work.

---

## Why Claude Code Was Different

Claude Code isn't just another autocomplete tool. When the **Claude Code Web** launched in October 2025, I suddenly had two complementary ways to work:

### Claude Code CLI
I use this for deep, focused work on my local machine:
- Terminal-based, which fits my existing workflow
- Full access to my filesystem and tools
- Custom hooks (more on this later—game changer)
- I mostly use it for infrastructure and backend work

### Claude Code Web (NEW - October 2025)
This became my go-to for parallel workflows:
- **No setup needed** - just opened my browser
- **Cloud-based parallel processing** - I could run multiple tasks at once
- **Mobile support** - I've actually done code reviews on my iPhone
- **Teleport feature** - seamlessly pulled work back to my CLI
- **Secure sandboxing** - each task in its own isolated environment

---

## How I Restructured My Development Process

I broke my workflow into three distinct phases:

### 1. Planning: Having Real Conversations with AI

I started using Claude Code Web for long-form architectural discussions. Instead of jumping straight to code, I'd start conversations like:

<CodeBlock language="text" code={`Project: E-commerce checkout system
Stack: Next.js 15, Stripe, PostgreSQL
Goal: Add Apple Pay support
Constraints: Must work with existing payment flow
Security: PCI-DSS compliant

What architectural approaches should I consider?`}/>

The difference was night and day. I was getting thoughtful architectural input, discussing tradeoffs, and **documenting decisions** before writing a single line of code.

### 2. Development: Actually Collaborating with AI

I moved to Claude Code CLI for implementation, but with a crucial mindset shift: I stopped treating it like fancy autocomplete.

Now I use AI to handle boilerplate and routine tasks while I focus on business logic. The codebase-aware suggestions mean it actually understands my patterns.

**The key insight:** I don't just accept code—I **collaborate** on it. It's a conversation, not a vending machine.

### 3. Quality: Automated Enforcement with Hooks

This is where everything clicked. Claude Code Hooks (released June 2025) let me turn my quality standards into **guaranteed actions** instead of hoping AI would remember them.

---

## The Hook Discovery That Changed Everything

Hooks are shell commands that run at specific points in Claude Code's lifecycle. Instead of **asking** AI to run my linters or tests, I could **guarantee** they always run.

I discovered there are 8 lifecycle events I could tap into:

1. **UserPromptSubmit** - Before Claude processes my prompt
2. **PreToolUse** - Before any tool execution
3. **PostToolUse** - After successful tool completion
4. **PreRead** - Before reading files
5. **PostWrite** - After writing files
6. **PostEdit** - After editing files
7. **Stop** - When the entire task completes
8. **Notification** - For user prompts or alerts

### The Hooks I Actually Use

#### My First Hook: Auto-Formatting

I added this to `.claude/settings.json`:

<CodeBlock language="json" code={`{
  "hooks": {
    "PostEdit": {
      "command": "prettier --write {{file_path}} && eslint --fix {{file_path}}",
      "description": "Auto-format and lint edited files"
    }
  }
}`}/>

Now every file Claude edits gets automatically formatted and linted. No more style inconsistencies. No more forgetting to run prettier.

#### Automatic Testing That Saved Me

This one caught so many regressions:

<CodeBlock language="json" code={`{
  "hooks": {
    "PostToolUse": {
      "command": "if [[ {{tool_name}} == 'Write' || {{tool_name}} == 'Edit' ]]; then npm test -- {{file_path}}; fi",
      "description": "Run tests for modified files"
    }
  }
}`}/>

I get instant feedback when something breaks. It's like having continuous integration running locally.

#### Desktop Notifications for Long Refactors

I can kick off a complex refactoring and go grab coffee:

<CodeBlock language="json" code={`{
  "hooks": {
    "Stop": {
      "command": "osascript -e 'display notification \\"Claude Code task completed\\" with title \\"AI Development\\"'",
      "description": "Notify when session completes"
    }
  }
}`}/>

My Mac pings me when it's done. No more checking back every few minutes.

#### The Security Hook That Saved My Bacon

Remember those API keys I almost committed? This hook stopped that:

<CodeBlock language="json" code={`{
  "hooks": {
    "PostWrite": {
      "command": "npm audit --audit-level=moderate && git secrets --scan {{file_path}}",
      "description": "Scan for vulnerabilities and secrets"
    }
  }
}`}/>

Every file gets scanned before it touches git. I sleep better at night.

---

## How Parallel Workflows Changed My Fridays

I used to hate Fridays. That's when I'd tackle the backlog—fixing small bugs, updating docs, refactoring old code. Context switching killed me.

Then I discovered Claude Code Web's parallel processing:

### My Old Sequential Approach:
1. Fix authentication bug → 30 minutes
2. Update API documentation → 20 minutes
3. Refactor database queries → 45 minutes

**Total time: 95 minutes** of constant context switching

### What I Do Now:
1. Open Claude Code Web and launch all three tasks simultaneously
2. Each runs in its own sandbox with full AI attention
3. I review and merge when they're done

**Total time: 45 minutes** (just the longest task, not all three added together)

### My Typical Friday Workflow Now

I open `claude.com/code` and queue up multiple tasks:
- "Fix authentication timeout in `auth/session.ts`"
- "Update API docs for new endpoints"
- "Optimize N+1 queries in user dashboard"

Each runs in isolation. When they're done, I use the **Teleport feature** to pull everything back to my local CLI for final review.

I've reclaimed my Fridays.

---

## Measuring What Actually Changed

I didn't want to fall into that "19% slower" trap, so I started tracking my work:

### My First Week (Baseline):
- Time to implement a typical feature: ~8 hours
- Bugs found in code review: 4-5 per feature
- Test coverage: hovering around 65%

### Four Weeks Later:
- Time to implement comparable features: ~4 hours
- Bugs found in code review: 2-3 per feature
- Test coverage: consistently above 80%

**What I noticed:**
- ✅ Routine tasks went **50% faster** (refactoring, boilerplate, etc.)
- ✅ Code quality stayed the same or improved in reviews
- ✅ Test coverage went up because AI actually writes comprehensive tests
- ✅ I spend way more time thinking about architecture now

---

## How My Thinking Changed

The biggest shift wasn't the tools—it was how I think about coding.

### How I Used to Work (AI as Autocomplete):
```
Me: *types code*
AI: *suggests next line*
Me: *accepts or rejects*
```

### How I Work Now (AI as Collaborator):
```
Me: "Here's the problem, constraints, and context"
AI: "Here are 3 architectural approaches"
Me: "Let's go with approach 2, but modify X"
AI: *implements with hooks ensuring quality*
Me: *reviews architecture, AI handles details*
```

### What I Care About Now vs. Then

**What matters less to me now:**
- Remembering exact syntax
- Writing boilerplate code
- Routine debugging tasks

**What I spend my energy on:**
- **Context engineering** - Giving AI the right information to work with
- **Architecture thinking** - Designing systems instead of just coding features
- **Quality orchestration** - Building automated quality gates with hooks
- **AI collaboration** - Knowing when to use AI and when to code myself

---

## My Current Development Stack

Here's what my 2025 workflow looks like now:

### Planning & Architecture
- **Claude Code Web** - When I need to explore multiple solutions in parallel
- **Claude Code CLI** - For deep architectural conversations about complex problems

### Implementation
- **Claude Code CLI with hooks** - My main development environment
- **GitHub Copilot** - I still use this occasionally for quick inline suggestions

### Quality & Automation
- **Custom hooks** - All my linting, testing, and formatting runs automatically
- **CI/CD integration** - I've even started using Claude Code in headless mode for automation

### Reflection
- **Weekly retrospectives** - I track what's working and what's not
- **Simple metrics** - Time saved, quality maintained, bugs caught

---

## Advanced Hook Patterns I've Discovered

Once I got comfortable with individual hooks, I started combining them into workflows.

### My Quality Pipeline

I built a progressive quality system that catches different issues at each stage:

<CodeBlock language="json" code={`{
  "hooks": {
    "PostEdit": {
      "command": "prettier --write {{file_path}}",
      "description": "Format code"
    },
    "PostWrite": {
      "command": "npm run lint:fix && npm run type-check",
      "description": "Lint and type-check"
    },
    "Stop": {
      "command": "npm test && npm run build",
      "description": "Ensure tests and build pass"
    }
  }
}`}/>

Every change goes through: format → lint → type-check → test → build. It's like having a mini-CI/CD running on every change.

### Auto-Documentation That Actually Works

I got tired of docs falling out of sync with code:

<CodeBlock language="json" code={`{
  "hooks": {
    "PostWrite": {
      "command": "if [[ {{file_path}} == *'.ts' ]]; then typedoc {{file_path}}; fi",
      "description": "Auto-generate TypeScript docs"
    }
  }
}`}/>

Now my documentation updates automatically. It's one less thing to remember.

### The Production Safety Net

After a close call with accidentally modifying production code, I added this:

<CodeBlock language="json" code={`{
  "hooks": {
    "PreToolUse": {
      "command": "if [[ {{tool_name}} == 'Write' && {{file_path}} == *'production'* ]]; then echo 'Blocked: Cannot modify production files'; exit 1; fi",
      "description": "Prevent accidental production changes"
    }
  }
}`}/>

It's like a safety switch on power tools—prevents catastrophic mistakes.

---

## Mistakes I Made (So You Don't Have To)

### Trusting AI Blindly
Early on, I'd accept AI suggestions without really reviewing them. Bad idea.

**What changed:** I set up mandatory code review hooks and never skip PR processes anymore, even for AI-generated code.

### Not Giving Enough Context
The AI would generate code that technically worked but didn't fit my codebase at all.

**What changed:** I created project context documents and learned to write better, codebase-aware prompts.

### Skipping Quality Gates
I let AI-generated code bypass my normal standards—no tests, no linting, nothing.

**What changed:** Hooks. Every piece of code goes through the same quality gates now.

### Using AI for Everything
I was using AI even for trivial one-line changes. Massive overkill.

**What changed:** I save AI for complex problems and handle simple changes manually. It's faster.

---

## How My Typical Day Looks Now

### Morning (5 minutes)
I check my Claude Code Web task queue, plan which work gets AI assistance, and update project context if anything changed.

### During Development
- **Complex features:** I start with a conversation in Claude Code Web
- **Parallel work:** I launch multiple tasks at once and go do something else
- **Local refinement:** When tasks finish, I use Teleport to pull work to my CLI
- **Quality checks:** My hooks handle this automatically—I barely think about it

### Evening (5 minutes)
I review what AI helped with versus what I coded manually. I document patterns that worked and update my hooks based on what I learned.

---

## What I've Noticed Over Time

The DORA 2025 report says that AI adoption correlates with small gains in productivity (+2.1%), flow (+2.6%), job satisfaction (+2.2%), and code quality (+3.4%).

But here's what they don't tell you: **these gains compound**.

**Month 1:** I was slower. Learning curve is real.
**Month 3:** I broke even with my old methods.
**Month 6:** I was 50% faster on routine tasks.
**Month 12:** I'm building projects I couldn't have tackled solo before.

This isn't about typing code faster—it's about **expanding what I'm capable of building**.

---

## How I Got Started (My First Week)

### Day 1-2: Setup
I installed Claude Code CLI, tried the Web version, and created my first hook—just a simple auto-formatter.

### Day 3-4: Learning
I read Osmani's "Beyond Vibe Coding" book, practiced giving better context to AI, and experimented with parallel workflows in the Web version.

### Day 5-6: Going Deeper
I started composing multiple hooks together, played with the Teleport feature, and built my first quality pipeline.

### Day 7: Taking Stock
I compared my productivity metrics from the week, documented what actually worked, and planned what to focus on next.

---

## Looking Back, Looking Forward

**Vibe coding** was fun while it lasted. It felt fast, productive, exciting.

But it was a playground, not a production system.

Now, with Claude Code's CLI and Web working together, hooks ensuring my quality standards, and structured workflows replacing my old ad-hoc prompting, I'm not just coding faster—**I'm building software I couldn't have built alone before**.

I still catch myself slipping into vibe coding mode sometimes. The difference is, now I notice it and course-correct.

The question isn't whether to use AI. The question is: **Will you use it strategically, or just keep winging it?**

---

<div className="bg-gradient-to-r from-blue-600 to-purple-600 text-white p-8 rounded-lg text-center my-8">
  <h2 className="text-2xl font-bold mb-4">Where I Am Now</h2>
  <p className="text-lg mb-6">
    Six months ago, I was vibe coding and wondering why AI made me slower.
    Today, I'm building things I couldn't have built alone.
  </p>
  <div className="grid md:grid-cols-2 gap-4 mt-6">
    <div className="bg-white/10 p-4 rounded-lg">
      <h3 className="font-semibold mb-2">Claude Code Web</h3>
      <p className="text-sm">I use this daily at claude.com/code</p>
    </div>
    <div className="bg-white/10 p-4 rounded-lg">
      <h3 className="font-semibold mb-2">Custom Hooks</h3>
      <p className="text-sm">My quality gates run automatically now</p>
    </div>
  </div>
</div>

**What I'd do differently if I started today:**
1. Skip the vibe coding phase entirely
2. Set up one hook on day one (auto-formatting)
3. Track metrics from the beginning
4. Focus on context engineering, not prompt engineering

**The shift isn't about tools—it's about how you think about building software.**

---

## Sources & Further Reading

1. [Beyond Vibe Coding - Addy Osmani](https://beyond.addy.ie/)
2. [Claude Code on the web - Anthropic](https://www.anthropic.com/news/claude-code-on-the-web)
3. [Claude Code Hooks Guide - Anthropic Docs](https://docs.claude.com/en/docs/claude-code/hooks-guide)
4. [Measuring AI Developer Productivity - Nicole Forsgren](https://www.lennysnewsletter.com/p/how-to-measure-ai-developer-productivity)
5. [DORA Report 2025 - Google](https://blog.google/technology/developers/dora-report-2025/)
6. [Measuring Impact of Early-2025 AI on Developer Productivity - METR](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/)

export default function Page({ children }) {
  return (
    <MdxLayout metadata={metadata} slug={BEYOND_VIBE_CODING.slug}>
      {children}
    </MdxLayout>
  );
}
